---
title: "Handling the habitatmap"
date: '`r paste("Version",lubridate::now())`'
output:
  html_document:
    number_sections: yes
    code_folding: show
    includes:
      in_header: ../header.html
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
---

```{r setup, message=FALSE, echo=FALSE}
options(stringsAsFactors = FALSE)
library(sf)
library(dplyr)
library(stringr)
library(tidyr)
library(n2khab)
library(knitr)
library(tmap)
library(leaflet)
opts_chunk$set(
  echo = TRUE,
  dpi = 300
)
```


# A few checks of the habitatmap data source

Interim version 3/2025

```{r read-habitatmap}
filepath <- file.path(fileman_up("n2khab_data"),
                      "10_raw/habitatmap")

if (length(grep("gpkg", list.files(path = filepath))) > 0){
  # format = geopackage
  filepath <- file.path(filepath, "habitatmap.gpkg")
  habitatmap <- st_read(filepath) 
  # omit layer name because it can be inconsistent in interim versions
} else 
  {
  # format = shapefile
    filepath <- file.path(filepath, "habitatmap.shp")
  habitatmap <- st_read(filepath, layer = "habitatmap")
}

```

The number of rows is `r nrow(habitatmap)`.

Checksums:
```{r checksums}
filepath %>% 
  n2khab::md5sum() %>% 
  `names<-`("md5sum")
filepath %>% 
  n2khab::sha256sum() %>% 
  `names<-`("sha256sum")
filepath %>% 
  n2khab::xxh64sum() %>% 
  `names<-`("xxh64sum")
```

## Field names

```{r field-names}
names(habitatmap)
```

Some names are in uppercase, others in lowercase or mixed case.
This is different from version 2023 (where all the field names were in uppercase).
A few fields were dropped since version 2023: `OIDN`, `UIDN`, `BWKLABEL`, `HABLEGENDE`, `LENGTE`, `OPPERVL`.
Other fields were added: `referentie`, `info`, `globalid_BWK`.
And the following names were changed: 

- `HERK` => `herk_bwk`
- `HERKHAB` => `HERK_HAB`
- `HERKPHAB` => `HERK_pHAB`
- `SHAPE_Leng` => `Shape_Length` (probably due to the fact that the previous version was a shapefile)

I convert all the field names to lowercase and remove all the underscores.
(only for this script: to be able to use the checks in this script with different 
versions of the habitatmap without the need to modify every chunk)

```{r lowercase-no-underscore}
names(habitatmap) <- tolower(gsub("_","",names(habitatmap)))
```



## A summary of the layer for version 3/2025

```{r summary-habitatmap}
habitatmap %>% 
  st_drop_geometry %>% 
  summary
```
Let us look for possible errors.

## Are there `NA` values?

There are no `NA`'s.

```{r na-values}
sapply(habitatmap, function(x) sum(is.na(x)))
```

## Are there `<Null>` values?

There is one `<Null>` string.

```{r null-values}
sapply(habitatmap |> st_drop_geometry(), function(x) sum(as.character(x) == '<Null>', na.rm = TRUE))
```

```{r}
habitatmap |> st_drop_geometry() %>% 
  filter(tag == "07_07315_22")
```

## Are there Zero (0) values?

Yes,  in `phab2`, `phab3`, `phab4`, `phab5` (as expected), but also a few in `tag`.

```{r zero-values}
sapply(habitatmap |> st_drop_geometry(), function(x) sum(as.character(x) == '0', na.rm = TRUE))
```

```{r}
habitatmap |> st_drop_geometry() %>% 
  filter(tag == '0')
```

## Are there empty strings instead of NA?

There are many empty strings (apparently used instead of NA's), in most of the cases in the fields where empty values can be expected though.

```{r empty-strings}
sapply(habitatmap |> st_drop_geometry(), function(x) sum(as.character(x) == '', na.rm = TRUE))
```

The following records might need to be checked since we don't expect empty values in the fields `eval`, `eenh1`, `herkbwk`, `hab1`, `herkhab`, `herkphab`.

```{r}
habitatmap |> st_drop_geometry() %>% 
  select(objectid, tag, eval, eenh1, eenh2, herkbwk, 
         hab1, phab1, herkhab, herkphab, globalidbwk ) %>% 
  filter(eval == '' |
           eenh1 == '' |
           herkbwk == '' |
           hab1 == '' |
           herkhab == '' |
           herkphab == '' ) # tag negeer ik (te veel)
```

As for `tag`: there are plenty of empty records in this interim versions. 
The `tag`will be added for the publication. In the meantime we might use
`globalidbwk`. 

## Are there spaces instead of NA?

There are records with one or several spaces.

```{r spaces}
sapply(habitatmap |> st_drop_geometry(), function(x) sum(grepl(pattern = "^\\s+$", x), na.rm = TRUE))
```

As for `tag` and `eenh2` until `eenh8`, ...: there are too many of them to print the list. 
Here are the cases with spaces for the other variables: 

```{r}
habitatmap |> st_drop_geometry() %>% 
  select(objectid, tag, eval, eenh1, eenh2, herkbwk, 
         hab1, phab1, herkhab, herkphab, globalidbwk ) %>% 
  filter(grepl(pattern = "^\\s+$", eval) & nchar(eval) > 0|
           grepl(pattern = "^\\s+$", eenh1) & nchar(eenh1) > 0|
           grepl(pattern = "^\\s+$", herkbwk) & nchar(herkbwk) > 0|
           grepl(pattern = "^\\s+$", hab1)  & nchar(hab1) > 0|
           grepl(pattern = "^\\s+$", herkhab) & nchar(herkhab) > 0|
           grepl(pattern = "^\\s+$", herkphab) & nchar(herkphab) > 0) 
```


## Are tag codes unique?

Even if we remove the records with `tag` = 0, there are duplicates

```{r}
habitatmap$tag %>% unique %>% length == nrow(habitatmap)

habitatmap$tag[habitatmap$tag != '0'] %>% unique %>% length == (nrow(habitatmap) - 1)

```
How many repeated TAG's?
```{r}
habitatmap |> st_drop_geometry() %>% 
  count(tag) %>% 
  filter(n > 1) %>% 
  nrow()

```

And is globalidbwk unique?

```{r}
habitatmap$globalidbwk %>% unique %>% length == nrow(habitatmap)
```

From here on I will use `globalidbwk` as identifier (in a new `id` field that 
can be used with any version of the habitatmap). 

```{r add-id}
habitatmap <- habitatmap %>% 
  mutate(id = globalidbwk)
```

## Are the habitat codes correct?

rbbvos+ should be rbbvos, the rest seems ok.

```{r check-types}
# read standard types from n2khab
list_habs <- n2khab::read_types()

# long version with all the habitats in one column
habitatmap_lg <- habitatmap %>% 
  st_drop_geometry() %>% 
  select(id, starts_with("hab")|starts_with("phab"), -any_of(c("HABLEGENDE", "hablegende"))) %>% 
  pivot_longer(cols = starts_with("hab"), 
               names_to = "habnr", 
               names_prefix = "hab", 
               values_to = "hab") %>%
  pivot_longer(cols = starts_with("phab"), 
               names_to = "phabnr", 
               names_prefix = "phab", 
               values_to = "phab") %>% 
  filter(habnr == phabnr) %>% 
  select(-phabnr)

# habitats in habitatmap but not in official list n2khab:
habitatmap_lg %>% 
  filter(!is.na(hab) & 
           !hab %in% c("gh", "", '<Null>') & 
           !grepl(pattern = "^\\s*$", hab)) %>%  
  mutate(hab = gsub(hab, pattern = ",gh", replacement = ""),
         hab = gsub(hab, pattern = ",bos", replacement = "")) %>% 
  anti_join(list_habs, by = c("hab" = "type")) %>% 
  count(hab) 
```

"x" is used for unknown (for instance private domain)

## Is the sum of the phab 100%?

There should not be any row returned with sum phab < 100% or > 100% 
(excepted when habitat 1130 is present):

```{r sum-phab-100}
habitatmap %>% 
  st_drop_geometry() %>% 
  mutate(phab_tot = phab1 + phab2 + phab3 + phab4 + phab5) %>% 
  filter(phab_tot < 100 |
           (phab_tot > 100 & hab1 != "1130")) %>% 
  nrow()
```


## Are there habitats with phab = 0%?

Yes: many!
Mostly used for habitats only present on a small surface, for instance as small 
landscape elements.

```{r phab0}

habitatmap_lg %>% 
  filter(
    !(
      is.na(hab) |
        hab %in% c("gh", "", '<Null>') |
        grepl(pattern = "^\\s*$", hab) 
    )
    & 
      phab == 0 ) %>% 
  nrow()

```

## Is the CRS correct?

Checking the CRS stated in the file as "`r st_crs(habitatmap)$input`": does it actually conform to the EPSG standard (in order to prevent CRS clashes in workflows)?

Does it conform to EPSG:31370?

Yes


```{r check-crs}
st_crs(habitatmap) == st_crs(31370)

st_crs(habitatmap)
```


## Validity of the geometries

Let's inspect features with invalid or corrupt geometry:

```{r check-geometry}
# can run for a while! (several minutes)

start_time <- Sys.time()

#st_is_valid(habitatmap) %>% table
validities <- st_is_valid(habitatmap)
invalid_geoms <- habitatmap[!validities | is.na(validities), ]
end_time <- Sys.time()
end_time - start_time

# important: since we need several minutes to calculate invalid_geoms, it is probably not 
# an option to use the same code as in read_watersurfaces
# the calculation of n_invalid would be too slow, so probably better to drop the if
# taken from read_watersurfaces: 
 # if (fix_geom) {
 #      n_invalid <- sum(
 #        !st_is_valid(watersurfaces) | is.na(st_is_valid(watersurfaces))
 #      )
 #      if (n_invalid > 0) {
 #        watersurfaces <- st_make_valid(watersurfaces)
 #        message("Fixed ", n_invalid, " invalid or corrupt geometries.")
 #      }
 #    }

```

```{r count-invalid-geoms}
st_is_valid(invalid_geoms, reason = TRUE) %>%
  as_tibble() %>%
  filter(value != "Valid Geometry") %>% 
  mutate(problem = str_extract(string = value, 
                                pattern = "[^\\[]+")) %>% 
  count(problem) 

```
The geometry invalidity is the consequence of self-intersecting rings, as a consequence of digitalization errors.

st_make_valid gives an error with this dataset "GeometryFixer::getResult called on unknown geometry type"
In this version there are apparently exotic geometry types: CURVEPOLYGON, COMPOUNDCURVE, 
CIRCULARSTRING ...

```{r}
unique(st_geometry_type(invalid_geoms))

# an example of multisurface:
invalid_geoms$geom[[33]]
```

From there on there is still some work to get it running

Let us take a look at the invalid polygons:

```{r graph-invalid-geoms, eval = FALSE}
# only use this if there are not too many invalid polygons
tm_shape(invalid_geoms) + tm_borders() + tm_facets(by = "tag")
```

```{r map-invalid-geoms, eval = FALSE}
# there are many invalid polygons, so we show them with leaflet:
invalid_geoms_wgs84 <- invalid_geoms %>% 
  st_transform(crs = 4326) 

leaflet(height = "600px", width = "700px") %>%
  addTiles(group = "OSM (default)") %>%
  addPolygons(data = invalid_geoms_wgs84,
              color = "darkred",
              popup = paste("tag:", 
                          invalid_geoms_wgs84$tag)) 
```

Let's compare with the same geoms after fixing the self-intersecting rings:

```{r make-valid-geom, eval = FALSE}
valid_geoms <- st_make_valid(invalid_geoms)
```

```{r graph-corrected-geoms, eval = FALSE}
# only use this if there are not too many invalid polygons
tm_shape(valid_geoms) + tm_borders() + tm_facets(by = "tag")
```

```{r map-corrected-geoms, eval = FALSE}
# there were many invalid polygons, so we show them with leaflet:
valid_geoms_wgs84 <- valid_geoms %>% 
  st_transform(crs = 4326) 

leaflet(height = "600px", width = "700px") %>%
  addTiles(group = "OSM (default)") %>%
    addPolygons(data = invalid_geoms_wgs84, 
                group = "before correction (red)",
                color = "darkred") %>% 
  addPolygons(data = valid_geoms_wgs84,
              group = "after correction (blue)",
              popup = paste(
                           "tag:",
                          valid_geoms_wgs84$tag)) %>%
    addLayersControl(overlayGroups = c("before correction (red)", "after correction (blue)"),
                     options = layersControlOptions(collapsed = FALSE))
```

Are all geometries valid now?

```{r recheck-geometry, eval = FALSE}
all(st_is_valid(valid_geoms))
```


So this works well. In the derived data (habitatmap_stdized) we will fix these geometries.

We also consider an optional geometry reparation step in `read_habitatmap(fix_geom = TRUE)`.

How long would it take to repair the geometries 'on the fly' while importing the habitatmap? 

```{r fix-geometry, eval = FALSE}

start_time <- Sys.time()
hmv <- st_make_valid(habitatmap)
end_time <- Sys.time()

end_time - start_time

```

OK, less than 1 minute sounds acceptable.

We also check that no empty geometries are present:

```{r check-empty-geom}
all(!is.na(st_dimension(habitatmap$geom)))
```

Refer to <https://github.com/inbo/n2khab-preprocessing/issues/60> and <https://r-spatial.org/r/2017/03/19/invalid.html> for more information!

# Tidyverse-styled, internationalized column names when using the data source in R

```{r eval = FALSE}
habitatmap %>% colnames %>% cat(sep = "\n")

```

data source variable          data frame variable
----------------------        ---------------------
`TAG`                         `polygon_id` (official version)
`globalid_BWK`                `polygon_id` (interim version)
`EVAL`                        `eval`
`EENH1`                       `eenh1`
`V1`                          `v1`
`HERK`                        `source`
`INFO`                        `info `
`BWKLABEL`                    `bwk_label`
`HAB1`                        `hab1`
`PHAB1`                       `phab1`
`HERKHAB`                     `source_hab`
`HERKPHAB`                    `source_phab`
`OPPERVL`                     `area_m2`

# Other considerations for the R object returned by `read_habitatmap()`

- not uptaking `OIDN`, `UIDN`, `HABLEGENDE`, `LENGTE`

# Used environment

```{r session-info, results = "asis", echo=FALSE}
si <- sessioninfo::session_info()
p <- si$platform %>%
  do.call(what = "c")
if ("sf" %in% si$packages$package) {
  p <- c(p, sf_extSoftVersion())
  names(p)[names(p) == "proj.4"] <- "PROJ"
}
if ("rgrass" %in% si$packages$package) {
  p <- c(p, GRASS = link2GI::findGRASS()[1, "version"])
}
sprintf("- **%s**: %s\n", names(p), p) %>%
  cat(sep = "")
```

```{r results = "asis", echo=FALSE}
si$packages %>%
    as_tibble %>%
    select(package, loadedversion, date, source) %>%
pander::pandoc.table(caption = "Loaded R packages",
                     split.table = Inf)
```
