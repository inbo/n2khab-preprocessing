# Making the data source

We will create a 'raw' data source `habitatquarries` by cleaning a precursor dataset.

```{r}
local_root <- find_root(has_file("generate_habitatquarries.Rproj"))
datapath <- file.path(local_root, "data")
if (!dir.exists(datapath)) dir.create(datapath)
```


## Load draft dataset

_This code is no longer executed because of the manual steps undertaken afterwards._
_Go directly to [manual updates](#manual-updates)._

```{r eval=FALSE}
drive_auth(email = TRUE)
drive_ls(as_id("1tJLjAlVbcNHcP4bgp7zRLS9e0KB9vyMs")) %>% 
  {map2(.$name, .$id, function(name, id) {
    drive_download(as_id(id),
               path = file.path(tempdir(), name),
               overwrite = TRUE)
  })} %>% 
  invisible()
```


```{r paged.print = FALSE, eval=FALSE}
habitatquarries <- read_sf(file.path(tempdir(), "8310_v2018_RAPHAB2019.shp"),
                        crs = 31370)
```

```{r paged.print = FALSE, eval=FALSE}
habitatquarries
```

## First standardization steps

_This code is no longer executed because of the manual steps undertaken afterwards._
_Go directly to [manual updates](#manual-updates)._

From common values of variables `id_old1` and `id_old2` in the below standardized dataset, we will derive a `unit_id` variable that represents somehow interconnected systems:

```{r paged.print = FALSE, eval=FALSE}
(habitatquarries <- 
   habitatquarries %>% 
   select(id_old1 = Id, 
          id_old2 = nr,
          name = Naam,
          type = HT8310,
          source = Bron))
```

Writing a derived dataset that contains the auto-generated `unit_id`:

```{r eval=FALSE}
habitatquarries %>% 
  st_drop_geometry %>% 
  count(id_old1, id_old2) %>% 
  filter(n > 1, id_old1 > 0 | id_old2 > 0) %>% 
  mutate(unit_id = 1:nrow(.)) %>% 
  select(-n) %>% 
  right_join(habitatquarries, by = c("id_old1", "id_old2")) %>% 
  select(-contains("old")) %>% 
  st_write(file.path(datapath,
                     "habitatquarries1.gpkg"),
           delete_dsn = TRUE)
```

## Manual updates

At this stage, `habitatquarries1.gpkg` has been copied to `habitatquarries2.gpkg` which was subsequently edited in **QGIS** 3.14:

- updated a truncated value for `source`;
- capitalized a lowercase name in `source`;
- added a few extra `unit_id` values for adjacent polygons and interconnected quarries;
- deleted 2 rows without geometry;
- updated the value of `type` for one polygon;
- updated the value of `name` for many polygons;
- updated the value of `source` for many polygons.

```{r eval=FALSE}
# Saving/updating the manually crafted habitatquarries2.gpkg in Google Drive:
drive_update(media = file.path(datapath, "habitatquarries2.gpkg"),
             file = as_id("1aM3hZqEp3ax66PCrhuyjwBZKd3EcALUS"))
```

## Final standardization and writing the resulting data source

Reading `habitatquarries2.gpkg` and turning it into a standardized data source:

```{r paged.print = FALSE}
drive_download(as_id("1aM3hZqEp3ax66PCrhuyjwBZKd3EcALUS"),
               path = file.path(tempdir(), "habitatquarries2.gpkg"),
               overwrite = TRUE)
habitatquarries <- read_sf(file.path(tempdir(), "habitatquarries2.gpkg")) 
# for spatial sorting:
centr <- 
  st_centroid(habitatquarries) %>% 
  st_coordinates()
habitatquarries %>% 
  mutate(x = centr[,"X"],
         y = centr[,"Y"]) %>% 
  arrange(unit_id, x, y) %>% 
  mutate(polygon_id = 1:nrow(.),
         unit_id = ifelse(is.na(unit_id),
                          100 + polygon_id,
                          unit_id) %>% 
                    as.integer,
         code_orig = ifelse(str_detect(type, "WAL|NL"),
                            NA_character_,
                            type),
         is_habitat = case_when(
           str_detect(type, "WAL|NL") ~ NA,
           str_detect(type, "8310") ~ TRUE,
           TRUE ~ FALSE
         ),
         type = ifelse(str_detect(type, "8310") & 
                         !str_detect(type, "WAL|NL"), 
                       "8310", 
                       NA_character_),
         source = ifelse(source == "", NA, source)) %>% 
  select(polygon_id,
         unit_id,
         name,
         code_orig,
         type,
         is_habitat,
         extra_reference = source) %>% 
  st_write(file.path(datapath, "habitatquarries.gpkg"),
           delete_dsn = TRUE)
```

# Adding the bibliography

## Creating a dataframe from the bibtex file

```{r warning=FALSE}
refs <- bib2df(file.path(datapath, "habitatquarries.bib"))
```


```{r}
refs2 <-
  refs %>% 
  map_lgl(function(col) any(!is.na(col))) %>% 
  refs[,.] %>% 
  `colnames<-`(tolower(colnames(.))) %>% 
  mutate(author = map_chr(author, 
                          function(x) paste(x, collapse = " and ")))
```


```{r}
glimpse(refs2)
```

Suggestion for making a function to read back as bibtex:

```{r eval=FALSE}
refs2 %>% 
  mutate(author = str_split(author, " and ")) %>% 
  `colnames<-`(toupper(colnames(.))) %>%
  df2bib
```

## Adding the dataframe to the GeoPackage

```{r}
refs2 %>% 
  st_write(file.path(datapath, "habitatquarries.gpkg"),
           layer = "extra_references",
           delete_layer = TRUE)
```



# Checks on the data source

```{r paged.print = FALSE}
read_sf(file.path(datapath, "habitatquarries.gpkg")) %>% 
  st_drop_geometry %>% 
  count(extra_reference)
```

