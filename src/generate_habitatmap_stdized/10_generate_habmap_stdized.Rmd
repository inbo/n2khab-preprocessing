# Generate standardized habitatmap

Interim version of the habitatmap as of March 2025 (official name: habitatmap_2024_v99_interim)

The interim habitatmap has not been cleaned up as well as the official published 
versions:
it contains inconsistent field names, the TAG field does not contain unique 
identifiers, the empty fields contain an empty string or one or more spaces, ...
(please refer to miscellaneous > habitatmap.Rmd for an full overview of the 
possible problems and needed corrections).

Because of these problems, it does not seem a good idea to load the raw version 
of the habitatmap with `n2khab::read_habitatmap` (there would be many corrections 
needed in `n2khab::read_habitatmap`, and possibly different corrections for each 
new interim version of the habitatmap).
Therefore we decide to skip the raw habitatmap for the interim versions and to
start directly with the standardized version.

## Data source

- adapt this when we know where the interim versions will be stored - 
The shapefile of the interim versions of the BWK and Natura 2000 habitat map of 
Flanders can be downloaded [here](https://zenodo.org/record/10167695).

To be sure we will use the correct version of the data source (habitatmap_2024_v99_interim), 
we will derive the md5 file hashes and compare it to the file hashes in the 
[data source version overview table](https://docs.google.com/spreadsheets/d/1E8ERlfYwP3OjluL8d7_4rR1W34ka4LRCE35JTxf3WMI/edit#gid=2100595853).

```{r}

path <- fileman_up("n2khab_data")
file <- "10_raw/habitatmap"

mypath <- file.path(path, file)

hashes <-
    tibble(filepath = str_c(mypath, "/",
        list.files(path = mypath,
            recursive = TRUE)
      )) %>%
    mutate(filename = str_match(filepath, "(.+\\/)*(.+)")[,3],
           md5 = map(filepath, function(x) {
                           file(x) %>% md5 %>% str_c(collapse = '')
                         }) %>% as.character,
           md5_ref = c("0421100ccd30f09f1060524324528232"),
           match = md5 == md5_ref) %>%
    select(filename,
           md5,
           md5_ref,
           match)

kable(hashes) %>%
  kable_styling()

if (!all.equal(hashes$md5, hashes$md5_ref)) {
    stop(cat("The source map is NOT up to date ! Please check  the datasource. "))
}
```


```{r read_raw_data}

habitatmap_sf <- st_read(file.path(path, file, "habitatmap.gpkg"),
                  #layer = "habitatmap", 
                  crs = 31370)

```

## Clean up of the interim version


```{r clean_up_interim}
# we want to make the interim version as similar as possible as the official one
# to avoid too many changes in the other chunks
habitatmap_sf <- habitatmap_sf %>% 
  rename(PHAB1 = pHAB1, # field names
         PHAB2 = pHAB2,
         PHAB3 = pHAB3,
         PHAB4 = pHAB4,
         PHAB5 = pHAB5) %>% 
  mutate(across(-geom, ~ifelse(grepl(pattern = "^\\s*$", .), NA, .)),
         info = ifelse(info == '<Null>', NA, info)) %>%  # clean up empty fields
   mutate(TAG = globalid_BWK) %>%  # add unique ID (we replace TAG by the unique globalid_BWK)
  rename(OPPERVL = Shape_Area) %>% 
  filter(!is.na(HAB1)) # remove a few errors

```


## Processing of the attribute table

Every polygon in the habitat map can consist of maximum 5 different vegetation types. This information is stored in the columns 'HAB1', 'HAB2',..., 'HAB5' of the attribute table. The estimated fraction of each vegetation type within the polygons is stored in the columns 'PHAB1', 'PHAB2', ..., 'PHAB5'.

We will convert the attribute table to a long format, so that every row contains one vegetation type.


```{r select_polygons}

habmap_sf <- habitatmap_sf %>%
            filter(!(HAB1 == "gh" & PHAB1 == 100)) %>%
            mutate(polygon_id = TAG, # unieke id
                   description_orig = str_c(PHAB1, "% ", HAB1,
                                      ifelse(is.na(HAB2), "", str_c("; ", PHAB2, "% ", HAB2)),
                                      ifelse(is.na(HAB3), "", str_c("; ", PHAB3, "% ", HAB3)),
                                      ifelse(is.na(HAB4), "", str_c("; ", PHAB4, "% ", HAB4)),
                                      ifelse(is.na(HAB5), "", str_c("; ", PHAB5, "% ", HAB5)))) 

```


```{r long_format}

habmap_longPHAB <- habmap_sf %>%
    st_drop_geometry() %>%
    gather(PHAB1, PHAB2, PHAB3, PHAB4, PHAB5, key = "phabn", value = "phab") %>%
    mutate(patch_id = str_sub(phabn, 5, 5)) %>%
    select(polygon_id, patch_id, phab) %>%
    filter(!is.na(phab))

habmap_longHAB <- habmap_sf %>%
    st_drop_geometry() %>%
    select(polygon_id, polygon_area = OPPERVL, 
           starts_with("HAB"), -any_of(c("HABLEGENDE"))) %>%
    gather(HAB1, HAB2, HAB3, HAB4, HAB5, key = "hab", value = "code") %>%
    mutate(patch_id = substr(hab, 4, 4)) %>%
    filter(!is.na(code)) %>%
    filter(!code %in% c("gh", "x"))

```

Here are the vegetation codes used in this version of the habitatmap:

```{r showListHabitats}
habmap_longHAB %>%
  distinct(code) %>% 
  arrange(code) %>% 
  kable(caption = "List codes in habitat map", label = NA) %>%
  kable_styling() %>% 
  scroll_box(height = "300px")
```

## Correction of some of the codes in the Habitat map

Some polygons in the habitat map contain codes that do not correspond with the standardized list of habitat types. 
We correct these codes to make processing of the habitat map more straightforward.
Table \@ref(tab:codeCorrected) shows the corrected codes and the number of polygons for which the correction is applied.


```{r }

habmap_correction <- read_vc("habmap_correction/habmap_correction")

overview_habmap_correction <- habmap_longHAB %>%
  inner_join(habmap_correction, by = "code") %>%
  group_by(code, code_corrected) %>%
  summarise(n_polygons = n()) %>%
  ungroup()

```


```{r codeCorrected}
overview_habmap_correction %>%
  kable(caption = "Corrected codes in habitat map", label = NA) %>%
  kable_styling()
```

```{r}
if(sum(habmap_correction$code %in% habmap_longHAB$code) > 0){

    habmap_longHAB <- habmap_longHAB %>%
        left_join(habmap_correction, by = "code") %>%
        mutate(code_orig = code,
            code = ifelse(is.na(code_corrected),
                             code,
                             code_corrected)) %>%
        select(-code_corrected)
    
    } else {
      
      habmap_longHAB <- habmap_longHAB %>%
        mutate(code_orig = code)
}
```


## Splitting codes that contain different types

In several cases the code contains 2 or 3 possible vegetation types which are separated with a ','. 
We will split the different possible vegetation types and create one row for each of them. 
An additional variable 'certain' will be FALSE if the orginal habitatmap code consists of 2 or 3 possible vegetation types, and TRUE if only one vegetation type is provided.

An exception to this rule are following codes: `3130_rbbmr`, `3140_rbbmr`, `3150_rbbmr` and `3160_rbbmr` (converted in the previous step into `31x0,rbbmr`).
These are standing water bodies that contain both `rbbmr` and the habitat type.
Therefore `certain` will be set to `TRUE` for both types included in `code`.

```{r}

habmap_long <- habmap_longHAB %>%
    left_join(habmap_longPHAB, by = c("polygon_id", "patch_id")) %>%
    mutate(certain = !str_detect(code, ","),
           certain = ifelse(code_orig %in% 
                              c("3130_rbbmr", "3140_rbbmr", "3150_rbbmr", "3160_rbbmr"), 
                            TRUE, 
                            certain)) %>%
    separate(code,
             into = c("type1", "type2", "type3"),
             sep = ",",
             remove = FALSE) %>%
    gather(type1, type2, type3, key = "ntype", value = "type") %>%
    filter(!is.na(type)) %>%
    filter(!(type %in% c("gh", "bos"))) %>%
    select(-patch_id)

```

Sometimes you get two records for the same type within the same habitatmap polygon.
We distinguish two cases: 

+ two certain or two uncertain records of the same type, for example:

```{r}
example <- habmap_long %>%
  group_by(polygon_id, type, certain) %>%
  add_count() %>% 
  filter(n > 1) %>%
  ungroup()

polygon_id_example_1 <- (example %>%
  slice_head(n = 1))$polygon_id

habmap_long %>%
  filter(polygon_id == polygon_id_example_1)
```

In this case we will sum the phab-values and create one record for each type.

+ a certain and an uncertain record of the same type, for example:

```{r}

example <- habmap_long %>%
  group_by(polygon_id, type) %>%
  filter(n() > 1) %>%
  filter(any(certain) & any(!certain)) %>%
  ungroup()

polygon_id_example_2 <- (example %>%
  slice_head(n = 1))$polygon_id

habmap_long %>%
  filter(polygon_id == polygon_id_example_2)
```

We will not aggregate the certain and uncertain record, because we will lose some information used to create `habitatmap_terr`. It is some of the uncertain records (such as `9120, gh`) are eliminated when processing `habitatmap_terr`. 

```{r}
check_double_type <- habmap_long %>%
  group_by(polygon_id, type) %>%
  mutate(n_type = n()) %>%
  ungroup() %>%
  filter(n_type > 1) %>% 
  arrange(polygon_id)
  
```


```{r}
habmap_long_aggr <- habmap_long %>%
  # group_by(polygon_id, code) %>%
  #     mutate(n = n()) %>%
  #   ungroup() %>%
    group_by(polygon_id, type, certain) %>%
     summarise(phab = sum(phab),
              code_orig = str_c(code_orig, collapse = "; "),
              certain = all(certain)) %>%
    ungroup() 
```
See below the result of the aggregation for the first example. 

```{r}
habmap_long_aggr %>%
  filter(polygon_id == polygon_id_example_1)
```

## Select vegetation types that belong to the standard list of habitat and rbb types  

Table \@ref(tab:selectTypes) shows the records with habitat types that do not belong to the standard list of habitat and rbb types.

Good news! 
The table is empty

```{r selectTypes}

types <- read_types() %>%
  select(type, typelevel, main_type, typeclass)

habmap_long_aggr <- habmap_long_aggr %>%
  left_join(types, by = "type")

habmap_types <- habmap_long_aggr %>%
  filter(!is.na(typelevel)) %>%
  select(polygon_id, type, certain, code_orig, phab) %>%
  mutate(type = factor(type,
                       levels = levels(types$type)
                       )
         ) %>%
  arrange(polygon_id, desc(phab))
  
habmap_other_type <- habmap_long_aggr %>%
  filter(is.na(typelevel))

habmap_other_type %>%
  select(polygon_id, type, certain, code_orig, phab) %>%
  kable(caption = "Polygons with types that do not correspond with the standard list of types and rbb",
        label = NA) %>%
  kable_styling()

```


## Select features that contain habitat or rbb types

```{r}

habmap_types_sf <- habmap_sf %>%
  select(polygon_id, description_orig) %>%
  filter(polygon_id %in% habmap_types$polygon_id)

```

## Let 's have a quick look at the result

In the official version, the ID of each polygon in the habitatmap contains the 
year in which the polygon was last updated.
In the table below we show the number of records per type and per update year.

```{r eval = FALSE}
# run only for the official versions with a TAG with the year as polygon_id
# polygon_id of the interim version does not contain the year 
habmap_types %>%
  mutate(polygon_version = str_sub(polygon_id, start = -4)) %>%
  group_by(type, polygon_version) %>%
  summarise(n_records = n()) %>%
  ungroup() %>%
  pivot_wider(names_from = "polygon_version", values_from = "n_records", values_fill = 0) %>%
  kable() %>%
  kable_styling()
```

## Control and fix geometries

We want to make sure that the layer has valid geometries so that we can use it 
in spatial analysis in GIS. 

First, we search for polygons with invalid geometries. 

```{r find_invalid_geoms}
validities <- st_is_valid(habmap_types_sf, reason = TRUE) %>%
  as_tibble() %>%
  mutate(id = rownames(.) ) %>%
  mutate(problem = str_extract(string = value,
                               pattern = "[^\\[]+")) %>%
  left_join(habmap_types_sf %>% 
              mutate(id = as.character(row_number())), 
            by = "id") %>% 
  select(-value)

# there are invalid polygons with a reason mentioned but also with no reason given (NA)
# those categories need to be handled separately

# invalid polygons with a clear explanation
habmap_types_geom_invalid <- validities %>%
  filter(problem != "Valid Geometry") 
# invalid polygons without a clear explanation: NA
habmap_types_geom_invalidna <- validities %>% 
  filter(is.na(problem)) 

cat(paste0("There are ", 
           rbind(habmap_types_geom_invalid,habmap_types_geom_invalidna) %>% nrow(), 
           " polygons with invalid geometry: \n", 
           habmap_types_geom_invalid %>% nrow() , 
           " with a clear explanation for the problem and \n",
           habmap_types_geom_invalidna %>% nrow(), 
           " without any clear explanation (NA)."))
```

```{r}
habmap_types_geom_invalid  %>%
  rbind(., habmap_types_geom_invalidna) %>% 
  select(id, polygon_id, description_orig, problem) %>% 
  kable(caption = "Polygons with faulty geometries", label = NA) %>%
  kable_styling() %>% 
  scroll_box(height = "300px")
```

We will correct the geometry using the function `st_make_valid` and check the results.

The interim version (habitatmap_2024_v99_interim) contains more exotic geometries (MULTISURFACE with curved polygons) that cannot be corrected directly.
We need an intermediate step to make it work: we convert the curved polygons into standard polygons with `gdalUtilities::ogr2ogr`.

```{r convert_curve_to_line}
# convert curved polygons into normal polygons
# this needs to be done for the NA only

st_write(habmap_types_geom_invalidna,
         './habmap_types_invalidna.gpkg',
         layer = "habmap_stdized_invalidna",
         driver = "GPKG",
         delete_dsn = TRUE)

gdalUtilities::ogr2ogr('./habmap_types_invalidna.gpkg',
                       './habmap_types_invalidnacorr.gpkg',
                       explodecollections = T, nlt = 'CONVERT_TO_LINEAR')

habmap_types_geom_invalidnacorr <- st_read("./habmap_types_invalidnacorr.gpkg")
# note the geometry type: POLYGON

file.remove('./habmap_types_invalidna.gpkg') 
file.remove('./habmap_types_invalidnacorr.gpkg')

# but there are now 181 records instead of 175
# duplicates
habmap_types_geom_invalidnacorr %>%
  st_drop_geometry() %>%
  count(polygon_id) %>%
  filter(n > 1)
# merge these polygons (see miscellaneous > habitatmap for the details)
habmap_types_geom_invalidnacorr_dissolved  <- habmap_types_geom_invalidnacorr %>%
  group_by(across(id:description_orig)) %>% 
  summarize(geom = sf::st_union(geom),
            .groups = "drop")

```

```{r}
# merge both invalid datasets back together

habmap_types_geom_invalidall <- habmap_types_sf %>% 
  inner_join(habmap_types_geom_invalid %>% 
               select(polygon_id, problem),
             by = join_by(polygon_id)) %>% 
  rbind(.,habmap_types_geom_invalidnacorr_dissolved %>% 
          select(-id))
```

Let us take a look at the invalid polygons:

```{r map_invalid_geoms}
# show the invalid polygons on a map
habmap_types_geom_invalid_wgs84 <- habmap_types_geom_invalidall %>%
  mutate(problem = ifelse(is.na(problem), "Unknown (NA)", problem)) %>% 
  st_transform(crs = 4326) 

pal <- colorFactor(palette = c("black", "darkred"), 
                   domain = habmap_types_geom_invalid_wgs84$problem)

leaflet(height = "600px", width = "700px") %>%
  addTiles(group = "OSM (default)") %>%
  addPolygons(data = habmap_types_geom_invalid_wgs84,
              color = pal(habmap_types_geom_invalid_wgs84$problem),
              popup = paste("polygon_id:", 
                          habmap_types_geom_invalid_wgs84$polygon_id, "<br>",
                           "description_orig:",
                          habmap_types_geom_invalid_wgs84$description_orig, 
                          "<br>", 
                          habmap_types_geom_invalid_wgs84$problem)) %>% 
  addLegend(data = habmap_types_geom_invalid_wgs84,
            pal = pal, values = ~problem,
            opacity = 1)
```


And now we can correct the geometries


```{r fix_geom}
# correct geometries

# combine all datasets (invalid and valid geoms)
habmap_types_geom_all <- habmap_types_sf %>% 
  semi_join(validities %>% 
              filter(!is.na(problem)) %>% # valid and invalid with ring
              select(polygon_id),
            by = join_by(polygon_id)) %>% 
  rbind(.,habmap_types_geom_invalidnacorr_dissolved %>% 
          select(-id, -problem)) # invalid with NA


# correct geometries
habmap_types_sf <- st_make_valid(habmap_types_geom_all)

```

```{r }
# list the corrected polygons and check the geometry again
habmap_types_geom_corrected <- st_is_valid(habmap_types_sf, reason = TRUE) %>% 
  as_tibble() %>% 
  mutate(id = rownames(.)) %>% 
  left_join(habmap_types_sf %>% 
              mutate(id = as.character(row_number())), 
            by = "id") %>% 
  filter(polygon_id %in% habmap_types_geom_invalidall$polygon_id)

habmap_types_geom_corrected %>% 
        select(id, polygon_id, description_orig, problem = value) %>% 
  kable(caption = "Polygons with faulty geometries after correction", 
        label = NA) %>% 
  kable_styling() %>% 
  scroll_box(height = "300px")
```


```{r map_corrected_geoms}
# show the corrected polygons on a map
habmap_types_geom_corrected_wgs84 <- habmap_types_sf %>% 
  filter(polygon_id %in% habmap_types_geom_invalidall$polygon_id) %>% 
  st_transform(crs = 4326) 

leaflet(height = "600px", width = "700px") %>%
  addTiles(group = "OSM (default)") %>%
    addPolygons(data = habmap_types_geom_invalid_wgs84, 
                group = "before correction (red)",
                color = "darkred") %>% 
  addPolygons(data = habmap_types_geom_corrected_wgs84,
              group = "after correction (blue)",
              popup = paste("polygon_id:", 
                          habmap_types_geom_corrected_wgs84$polygon_id, "<br>",
                           "description_orig:",
                          habmap_types_geom_corrected_wgs84$description_orig)) %>%
    addLayersControl(overlayGroups = c("before correction (red)", "after correction (blue)"),
                     options = layersControlOptions(collapsed = FALSE))
```


## Write results into a geopackage

```{r}
dir.create(file.path(path, "20_processed/habitatmap_stdized"), recursive = TRUE)
filepath <- file.path(path,"20_processed/habitatmap_stdized/habitatmap_stdized.gpkg")
```

```{r write_gpkg}

st_write(habmap_types_sf, 
         filepath, 
         layer = "habitatmap_polygons", 
         driver = "GPKG", 
         delete_dsn = TRUE)

st_write(habmap_types, 
         filepath, 
         layer = "habitatmap_types", 
         driver = "GPKG", 
         append = TRUE)
```
